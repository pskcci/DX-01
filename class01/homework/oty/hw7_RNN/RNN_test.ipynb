{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN test (RNN, LSTM, GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, GRU, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범위를 0 ~ 1 로 normalized\n",
    "def MinMaxScaler(data):\n",
    "    \"\"\"최솟값과 최댓값을 이용하여 0 ~ 1 값으로 변환\"\"\"\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # 0으로 나누기 에러가 발생하지 않도록 매우 작은 값(1e-7)을 더해서 나눔\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "# 삼성전자 주식 데이터\n",
    "df = fdr.DataReader('005930', '2018-05-04', '2024-11-24')\n",
    "dfx = df[['Open','High','Low','Volume', 'Close']]\n",
    "dfx = MinMaxScaler(dfx)\n",
    "dfy = dfx[['Close']]\n",
    "dfx = dfx[['Open','High','Low','Volume']]\n",
    "\n",
    "# 두 데이터를 리스트 형태로 저장\n",
    "x = dfx.values.tolist() # open, high, low, volume\n",
    "y = dfy.values.tolist() # close\n",
    "\n",
    "#ex) 1월 1일 ~ 1월 10일까지의 OHLV 데이터로 1월 11일 종가 (Close) 예측\n",
    "#ex) 1월 2일 ~ 1월 11일까지의 OHLV 데이터로 1월 12일 종가 (Close) 예측\n",
    "window_size = 10\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(len(y) - window_size):\n",
    "    _x = x[i : i + window_size] # 다음 날 종가(i+windows_size)는 포함되지 않음\n",
    "    _y = y[i + window_size] # 다음 날 종가\n",
    "    data_x.append(_x)\n",
    "    data_y.append(_y)\n",
    "               \n",
    "train_size = int(len(data_y) * 0.7)\n",
    "val_size = int(len(data_y) * 0.2)\n",
    "train_x = np.array(data_x[0 : train_size])\n",
    "train_y = np.array(data_y[0 : train_size])\n",
    "val_x = np.array(data_x[train_size:train_size+val_size])\n",
    "val_y = np.array(data_y[train_size:train_size+val_size])\n",
    "test_size = len(data_y) - train_size - val_size\n",
    "test_x = np.array(data_x[train_size+val_size: len(data_x)])\n",
    "test_y = np.array(data_y[train_size+val_size: len(data_y)])\n",
    "print('훈련 데이터의 크기 :', train_x.shape, train_y.shape)\n",
    "print('검증 데이터의 크기 :', val_x.shape, val_y.shape)\n",
    "print('테스트 데이터의 크기 :', test_x.shape, test_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=20, activation='tanh',\n",
    "                     return_sequences=True,\n",
    "                     input_shape=(10,4)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(SimpleRNN(units=20, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error')\n",
    "history = model.fit(train_x, train_y,\n",
    "                    validation_data = (val_x, val_y),\n",
    "                    epochs=70, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU 모델\n",
    "model = Sequential()\n",
    "model.add(GRU(units=20, activation='tanh',\n",
    "return_sequences=True,\n",
    "input_shape=(10, 4)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GRU(units=20, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "loss='mean_squared_error')\n",
    "history = model.fit(train_x, train_y,\n",
    "validation_data = (val_x, val_y),\n",
    "epochs=70, batch_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=20, activation='tanh',\n",
    "return_sequences=True,\n",
    "input_shape=(10, 4)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(units=20, activation='tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "loss='mean_squared_error')\n",
    "history = model.fit(train_x, train_y,\n",
    "validation_data = (val_x, val_y),\n",
    "epochs=70, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 학습 과정의 손실 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "pred_y = model.predict(test_x)\n",
    "\n",
    "# 실제값 vs 예측값 그래프\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(test_y, label='True Values', color='blue')\n",
    "plt.plot(pred_y, label='Predicted Values', color='red', linestyle='--')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Close Price (Normalized)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 평가 지표 (MSE)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(f\"Mean Squared Error on Test Data: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
